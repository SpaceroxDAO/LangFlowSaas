"""
Auto-generated component for: Plane Experts
Created: 2026-01-10T01:28:13.990370
User ID: 974a39d3-3108-4e8a-a777-1ac44b87b17c
Component ID: 5f3534bf-33ec-43b4-9173-af65ea75c9c5

This component is a custom AI agent created through Teach Charlie AI's
3-step Q&A wizard. It wraps Langflow's Agent functionality with prefilled
configuration from the user's answers.

DO NOT EDIT THIS FILE MANUALLY - it will be regenerated when the agent
is republished.
"""
from langflow.custom import Component
from langflow.io import (
    MessageTextInput,
    Output,
    DropdownInput,
    SecretStrInput,
    SliderInput,
    IntInput,
    BoolInput,
    MultilineInput,
    HandleInput,
    DataInput,
)
from langflow.schema.message import Message
from langflow.field_typing import Tool
from langflow.field_typing.range_spec import RangeSpec


class PlaneExpertsAgent_5f3534bf(Component):
    """Created from Q&A wizard"""

    display_name = "Plane Experts"
    description = "Created from Q&A wizard"
    icon = "dog"
    name = "PlaneExpertsAgent_5f3534bf"

    inputs = [
        # User Message Input
        MessageTextInput(
            name="input_value",
            display_name="Message",
            info="Enter your message or question for Plane Experts",
            tool_mode=True,
        ),

        # Model Configuration (visible by default)
        DropdownInput(
            name="model_provider",
            display_name="Model Provider",
            options=["OpenAI", "Anthropic", "Google", "Azure OpenAI"],
            value="OpenAI",
            info="The LLM provider to use for this agent",
        ),
        DropdownInput(
            name="model_name",
            display_name="Model Name",
            options=[
                "gpt-4o-mini", "gpt-4o", "gpt-4-turbo", "gpt-3.5-turbo",
                "claude-3-haiku-20240307", "claude-3-sonnet-20240229", "claude-3-opus-20240229",
                "gemini-1.5-flash", "gemini-1.5-pro",
            ],
            value="gpt-4o-mini",
            info="The specific model to use",
            combobox=True,
        ),
        SecretStrInput(
            name="api_key",
            display_name="API Key",
            info="Your API key for the selected provider (leave blank to use environment variable)",
            required=False,
        ),

        # Agent Instructions (PREFILLED from Q&A - the core value!)
        MultilineInput(
            name="agent_instructions",
            display_name="Agent Instructions",
            info="Instructions that define how Plane Experts behaves",
            value="""You are You love planes.\n\n## Your Rules and Knowledge\nyou know the size of planes and how many people they carry\n\n## Important Guidelines\n- Always stay in character as described above\n- Be helpful, friendly, and professional\n- If you don't know something, admit it honestly\n- Keep responses concise but informative\n- Ask clarifying questions when needed\n- Use your available tools when they can help answer questions\n\n## Your Tools\nYou have access to the following tools:\n- Knowledge Search: Search through your uploaded documents and knowledge sources\nUse these tools when appropriate to provide accurate, up-to-date information.""",
        ),

        # Tools Input
        HandleInput(
            name="tools",
            display_name="Tools",
            input_types=["Tool", "BaseTool", "StructuredTool"],
            is_list=True,
            info="Tools that Plane Experts can use to help answer questions",
        ),

        # Advanced Options (hidden by default)
        SliderInput(
            name="temperature",
            display_name="Temperature",
            value=0.7,
            range_spec=RangeSpec(min=0, max=2, step=0.01),
            info="Controls randomness in responses. Lower = more deterministic, higher = more creative.",
            advanced=True,
        ),
        IntInput(
            name="max_tokens",
            display_name="Max Tokens",
            value=4096,
            range_spec=RangeSpec(min=1, max=128000),
            info="Maximum number of tokens in the response",
            advanced=True,
        ),
        IntInput(
            name="max_iterations",
            display_name="Max Iterations",
            value=10,
            range_spec=RangeSpec(min=1, max=100),
            info="Maximum number of reasoning steps the agent can take",
            advanced=True,
        ),
        BoolInput(
            name="verbose",
            display_name="Verbose Mode",
            value=False,
            info="Show detailed agent reasoning steps in the output",
            advanced=True,
        ),
        BoolInput(
            name="handle_parsing_errors",
            display_name="Handle Parsing Errors",
            value=True,
            info="Gracefully handle LLM output parsing errors instead of failing",
            advanced=True,
        ),
        DataInput(
            name="chat_history",
            display_name="Chat History",
            is_list=True,
            info="Previous messages for multi-turn conversation context",
            advanced=True,
        ),
    ]

    outputs = [
        Output(
            display_name="Response",
            name="response",
            method="run_agent",
        ),
        Output(
            display_name="As Tool",
            name="component_as_tool",
            method="to_toolkit",
        ),
    ]

    def run_agent(self) -> Message:
        """Execute the agent with the configured settings."""
        import os

        # Get API key from input or environment
        api_key = self.api_key
        if not api_key:
            if self.model_provider == "OpenAI":
                api_key = os.environ.get("OPENAI_API_KEY", "")
            elif self.model_provider == "Anthropic":
                api_key = os.environ.get("ANTHROPIC_API_KEY", "")
            elif self.model_provider == "Google":
                api_key = os.environ.get("GOOGLE_API_KEY", "")

        if not api_key:
            return Message(text="Error: No API key provided. Please enter your API key or set the environment variable.")

        # Select LLM based on provider
        try:
            if self.model_provider == "OpenAI":
                from langchain_openai import ChatOpenAI
                llm = ChatOpenAI(
                    model=self.model_name,
                    api_key=api_key,
                    temperature=self.temperature,
                    max_tokens=self.max_tokens or None,
                )
            elif self.model_provider == "Anthropic":
                from langchain_anthropic import ChatAnthropic
                llm = ChatAnthropic(
                    model=self.model_name,
                    api_key=api_key,
                    temperature=self.temperature,
                    max_tokens=self.max_tokens or 4096,
                )
            elif self.model_provider == "Google":
                from langchain_google_genai import ChatGoogleGenerativeAI
                llm = ChatGoogleGenerativeAI(
                    model=self.model_name,
                    google_api_key=api_key,
                    temperature=self.temperature,
                    max_output_tokens=self.max_tokens or 4096,
                )
            else:
                # Default to OpenAI
                from langchain_openai import ChatOpenAI
                llm = ChatOpenAI(
                    model=self.model_name or "gpt-4o-mini",
                    api_key=api_key,
                    temperature=self.temperature,
                )
        except ImportError as e:
            return Message(text=f"Error: Missing dependency for {self.model_provider}. Details: {str(e)}")
        except Exception as e:
            return Message(text=f"Error initializing LLM: {str(e)}")

        # Build tools list
        tools = self.tools if self.tools else []

        # Build chat history
        history = []
        if self.chat_history:
            for msg in self.chat_history:
                if hasattr(msg, 'data') and isinstance(msg.data, dict):
                    role = msg.data.get('role', 'user')
                    content = msg.data.get('content', '')
                    history.append((role, content))

        try:
            if tools:
                # Use agent with tools
                from langchain.agents import AgentExecutor, create_tool_calling_agent
                from langchain_core.prompts import ChatPromptTemplate

                prompt = ChatPromptTemplate.from_messages([
                    ("system", self.agent_instructions),
                    ("placeholder", "{chat_history}"),
                    ("human", "{input}"),
                    ("placeholder", "{agent_scratchpad}"),
                ])

                agent = create_tool_calling_agent(llm, tools, prompt)
                executor = AgentExecutor(
                    agent=agent,
                    tools=tools,
                    verbose=self.verbose,
                    max_iterations=self.max_iterations,
                    handle_parsing_errors=self.handle_parsing_errors,
                )

                result = executor.invoke({
                    "input": self.input_value,
                    "chat_history": history,
                })
                response_text = result.get("output", "")
            else:
                # No tools - just run LLM directly with system prompt
                from langchain_core.messages import SystemMessage, HumanMessage

                messages = [SystemMessage(content=self.agent_instructions)]
                for role, content in history:
                    if role == "user":
                        messages.append(HumanMessage(content=content))
                    else:
                        from langchain_core.messages import AIMessage
                        messages.append(AIMessage(content=content))
                messages.append(HumanMessage(content=self.input_value))

                response = llm.invoke(messages)
                response_text = response.content

            self.status = response_text
            return Message(text=response_text)

        except Exception as e:
            error_msg = f"Error running agent: {str(e)}"
            self.status = error_msg
            return Message(text=error_msg)

    def to_toolkit(self) -> list[Tool]:
        """Convert this component to a tool for use by other agents."""
        from langchain.tools import Tool as LangChainTool

        def run_as_tool(query: str) -> str:
            """Run this agent as a tool."""
            original_input = self.input_value
            self.input_value = query
            try:
                result = self.run_agent()
                return result.text if hasattr(result, 'text') else str(result)
            finally:
                self.input_value = original_input

        return [LangChainTool(
            name="PlaneExpertsAgent_5f3534bf",
            description="Created from Q&A wizard",
            func=run_as_tool,
        )]
