# =============================================================================
# Teach Charlie AI - Automated Database Backup Workflow
# =============================================================================
# Triggers: Daily at 3am UTC, manual dispatch
# Purpose: Automated database backups with optional S3 upload
#
# Requirements:
# - DEPLOY_HOST: Production server IP
# - DEPLOY_SSH_KEY: SSH private key for root access
# - AWS_ACCESS_KEY_ID: AWS credentials for S3 (optional)
# - AWS_SECRET_ACCESS_KEY: AWS credentials for S3 (optional)
# - BACKUP_S3_BUCKET: S3 bucket name for backups (optional)
# =============================================================================

name: Database Backup

on:
  schedule:
    # Run daily at 3am UTC
    - cron: "0 3 * * *"
  workflow_dispatch:
    inputs:
      upload_to_s3:
        description: "Upload backup to S3"
        required: false
        default: "false"
        type: boolean
      retention_days:
        description: "Days to keep backups"
        required: false
        default: "30"

jobs:
  backup:
    name: Backup Database
    runs-on: ubuntu-latest

    steps:
      - name: Run backup on production server
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.DEPLOY_HOST }}
          username: root
          key: ${{ secrets.DEPLOY_SSH_KEY }}
          script_stop: true
          script: |
            set -e

            echo "=== Starting Database Backup ==="

            # Configuration
            BACKUP_DIR="/root/backups/postgres"
            TIMESTAMP=$(date +%Y%m%d_%H%M%S)
            BACKUP_FILE="teachcharlie_${TIMESTAMP}.sql.gz"
            RETENTION_DAYS="${{ github.event.inputs.retention_days || '30' }}"

            # Create backup directory
            mkdir -p "${BACKUP_DIR}"

            # Check container is running
            if ! docker ps --format '{{.Names}}' | grep -q "^teachcharlie-postgres$"; then
                echo "ERROR: PostgreSQL container not running!"
                exit 1
            fi

            # Create backup
            echo "Creating backup: ${BACKUP_FILE}"
            docker exec teachcharlie-postgres pg_dump -U postgres teachcharlie | gzip > "${BACKUP_DIR}/${BACKUP_FILE}"

            # Verify backup
            if gzip -t "${BACKUP_DIR}/${BACKUP_FILE}"; then
                echo "Backup verified successfully"
                ls -lh "${BACKUP_DIR}/${BACKUP_FILE}"
            else
                echo "ERROR: Backup verification failed!"
                exit 1
            fi

            # Clean up old backups
            echo "Cleaning up backups older than ${RETENTION_DAYS} days..."
            find "${BACKUP_DIR}" -name "teachcharlie_*.sql.gz" -mtime +${RETENTION_DAYS} -delete

            # List current backups
            echo ""
            echo "=== Current Backups ==="
            ls -lh "${BACKUP_DIR}"/teachcharlie_*.sql.gz | tail -10

            # Calculate total backup size
            TOTAL_SIZE=$(du -sh "${BACKUP_DIR}" | cut -f1)
            echo ""
            echo "Total backup storage used: ${TOTAL_SIZE}"

            echo ""
            echo "=== Backup Complete ==="

      - name: Upload to S3 (optional)
        if: github.event.inputs.upload_to_s3 == 'true' && secrets.BACKUP_S3_BUCKET != ''
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.DEPLOY_HOST }}
          username: root
          key: ${{ secrets.DEPLOY_SSH_KEY }}
          script: |
            echo "Uploading latest backup to S3..."

            # Get latest backup file
            LATEST=$(ls -t /root/backups/postgres/teachcharlie_*.sql.gz | head -1)
            FILENAME=$(basename "${LATEST}")

            # Upload to S3 (requires AWS CLI on server)
            if command -v aws &> /dev/null; then
                aws s3 cp "${LATEST}" "s3://${{ secrets.BACKUP_S3_BUCKET }}/backups/postgres/${FILENAME}"
                echo "Uploaded to S3: ${FILENAME}"
            else
                echo "AWS CLI not installed, skipping S3 upload"
            fi

      - name: Notify on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Database Backup Failed - ${new Date().toISOString().split('T')[0]}`,
              body: `## Backup Failure\n\nThe automated database backup failed.\n\nWorkflow: ${context.workflow}\nRun: ${context.runId}\n\n**Action Required:** Investigate and ensure backups are running correctly.`,
              labels: ['backup', 'urgent']
            });
